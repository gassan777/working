All right. Welcome back everyone. This is the workflow and provenance week. This is the second video provenance. Of course we begin with what is provenance and of course we move on to why is provenance important and then a little bit about kinds of provenance. It's an interesting word. It's a little unusual in computer science. Appeared, I don't know, not that long ago in the history of computer science. So, we start by talking about the origin of the term this time. So, in general the, word provenance means the place of origin or earliest known history of something, and that's from the Oxford English Dictionary. In the humanities, it has a slightly more specialized meaning, particularly in art history. Refers to a record of ownership of a work, such as a work of art, or an antique, and this record is used as a guide to the authenticity or quality of the object. It has been adapted by, actually, biodata and science in general, but particularly by data curation. And we now use the phrase computational provenance to distinguish our sense of provenance, which is related from the others. So, computational provenance is the origin and processing history of an artifact, usually data, data products, figures, images, and so on. Sometimes, workflow and script evolution is also considered computational provenance. And that's from the project DataOne. W3C also has an account. It characterize computation provenance as the sources of information, including entities and processes, involved in producing or delivering an artifact. Computational provenance. The heart of computational provenance. I would say these two questions: What data was used? What calculations were performed? What data was used? What calculations were performed? What transformations occurred in other words? Why is provenance important? And I'm sure you know why, but just to be sure. Access to provenance information, which means you got to record it in a systematic way. Access to provenance information supports understanding, what we're looking at the end, the reliability of the process and the reliability of, in this case the, data, reproducibility, trust, attribution and credit. You need to know where your derived dataset came from, what the inputs were and what methods or calculations were used if you're going to give appropriate credit to the organizations, the people or even the algorithms themselves. And you need to do that. So, provenance is important for acquisition of credit. it's not always noted unlike the objectives earlier in the list. And this too, it's not always noted. The discovery and the reuse of data tools and algorithms is also supported by provenance. You can look at a process, you can look at the end result and say, wow, that's amazing. I want to do something like that. What data did they use? What tools did they use? What algorithms were applied? Provenance will help you answer that question so that you can use them too. It's nice to say that these are the advantages of having accessible provenance. That this is why accessible provenance is important, but let's see if we can make this a little scarier. So, the consequences of inadequate provenance information, of not having any or much or enough provenance information about a transformation process, can really be profound. It is scary. And it's not only restricted to failures of understanding, failures of reputation, and the abstract loss for liability trust, but also, big dangerous consequences such as the failure of transportation or power systems; medical systems, instruments, and therapies; failures of heavy machine operations. Really bad things can happen when you don't understand how you got the data you have, where it came from, what data it came from, and what calculations were performed. It's not reliable. It's not reliable unless you have ready access to relevant provenance information. Another thing, if you don't know what data you used or what transformations and methods and algorithms were applied, you can actually break the law or be vulnerable to civil penalties because you may be using data or methods that violate the property rights, you may even be using data that violate actual legal restrictions entailing criminal penalties. So, provenance it's not just a good idea for law. Homework now. You know I like to do a classification. And these levels of prominence come from Bertram Ludascher definitions or somewhat adapted by me, black-box, white-box, grey-box. So, in the black-box, the black-box level, little is explicitly and verifiably known about what data and methods are being used. You've got some programs, you've got some data, and you're running this scenario but you're not really able to look inside in a reasonably satisfying way. You're not able to study the tools, the scripts, the transformational instructions, and get a good grip on what's happening and why. In white-box provenance, quite the opposite. There you have a mathematically exact representation of the data and algorithms that are being used, and you can use that representation to draw lots of conclusions about the data that you've generated. In grey-box, box of the provenance, we have some purchase on the parts of our scenario. We can identify the datasets. We know where they came from. We know a little bit about structure. And we can identify the processes kind of by name, perhaps the name of a function, the name of the library. We kind of know what's going on, but we don't know at a sufficiently mathematically granular level exactly what the transformations are. We aren't really able to do calculations on the transformations which amount to calculations on the calculations. And finally, I'm going to end with another classification, this one also from Bertram Ludascher, prospect versus retrospective provenance. And this is a classification that makes the relationship between workflow and provenance clear I think. The terminology is Professor Ludascher's. So, in prospective provenance, what we have is documented workflow. We have a correct and mathematically clear and exact specification of the workflow scenario. In retrospective provenance, you might say this is classical provenance, we have generated data, typically we know trace data for instance, on the execution of a workflow scenario. So, not surprisingly there are sort of colloquial. I would somehow say slang expressions that Bertram invented along with this more respectable scholarly terminology here, prospective retrospective. He also refers to these as compile time provenance and runtime provenance or a workflow-land, where we're specifying workflows, and trace-land, where we're collecting data as the workflow runs. In the next video, we'll get a little better idea of how that happens and in particular how it happens in actual workflow systems. See you then.