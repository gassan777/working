Hi everyone. Welcome back. This week is devoted to data preservation. Data preservation is now, has always been a fundamental component to data creation and it is increasingly important in the environment that we're in now in the 21st century. And the rest of this video, I'm going to be talking about the general nature of data preservation and its importance. This is kind of a first pass. All the things that we're looking at now will be refined in more detail later. Okay, first, as I said, data preservation is a component of data curation. And you know it's not just a component of data curation, it's perhaps the exemplary component of data curation. It's important and it's fundamentally characteristic of what data curation is. Recall our central objective for data curation, to efficiently and reliably support the analysis of data and enable reuse over time. I assume you've all had this committed to memory, maybe you've tattooed it on your forearm or something. I haven't thought about it. At the risk of being repetitious, I'm going to say and enable the efficient and reliable reuse of data over time. That's what we're trying to do. We want to support the reuse of data that's important, that's expensive to develop, that's needed to solve important problems. We want to support its use over time and we want to support that use efficiently and reliably. Every word counts here. So, we want to do this despite, and here are the problems, despite physical deterioration or damage to our storage devices, to our disks for instance. The internal or granular decay of our digital representations, bit rot colloquially, but the problem is that just can't rely those little magnetic solid state devices to always stay in the state we want them to be in. Despite changes to file formats or encodings, despite changes to schemas and standards, despite changes to software tools and applications, history just rolls on. And all these things are happening all the time at a rate often a little faster than we expect. Another problem: the loss or separation of critical contextual information or documentation. And finally just changes in practices and expectations. All these things are going on all the time, and they all conspire to prove that the efficient and reliable reuse of data over time. So, our first definition, yep it's not good enough but it's good enough for now, of digital preservation is the active management of digital content over time to ensure ongoing access. That's from the US Library of Congress. I think they could have done a little bit better and you'll see why in the next video, but sufficient for now. Okay, I'm now going to summarize some preservation problems. I'm going to summarize them in three categories: obsolescence, physical threats and context. And all of these things will be expanded in the remaining videos. So obsolescence, one kind of obsolescence is file format obsolescence. There are software upgrades that don't support legacy files or format is superseded by another where it evolves in complexity in a way that's not going to be compatible with the software you're using or that won't allow datasets from back versions to be used at the same time. Another problem with file formats, file formats that are not compatible even with current operating systems. Can happen, has happened. And of course, I'm not sure that this really belongs in this list, but a company just goes out of business or is bought by a competitor. And then there are a cascade of problems involving formats and upgrades. Hardware and media obsolescence, so here the problem is the future, things happen. We have new, faster, computer and storage media with different operating systems and different compatibilities. We have changes in things like physical size or data transfer or even plugs and sockets and, of course, reliability and fragility of media which leads us to physical threats. So, as well as the fundamentally technological threats we just discussed another rubric of obsolescence, it's also a fact that the material media that we're using, the instances of material media are in the physical world and consequently they're subject to all the physical states of being in the digital world. That includes changes in temperature, humidity, light, dust, dirt, floods, fires, earthquakes, pipes bursting, electrical outages, sabotage, theft, vandalism. Makes our profession sound pretty exciting, doesn't it? And finally, some problems that might be called context problems. And I think it's best to see these through the lens of examples of meta data that must not be lost if you're going to use data reliably and efficiently in the future. For example, file format data you don't want some wondering in the future, is this ASCII or EBCDIC or something else? Is this TEI version 2.1 or version 5.0? You need to know these things. Data context, who collected these observations? Where and when and, perhaps most importantly, how? With what instruments? What do these attributes and values mean? What do these things mean? 10 years, 15 years, 20 years in the future, you don't want your future colleagues staring at this data wondering what does that attribute mean? Nor do you want them wondering how the values were calculated. To use data reliably and efficiently, we need to know that. To use it at all we need to know what the attributes and value mean. But to use it well, to use it reliably, to use it effectively, we need to know how were these values calculated? You don't want to lose that metadata. And there's processing metadata as well. You want your future colleagues to know what software created this file. And perhaps more importantly, what software can read and process it? Obviously, very important and I suspect that all of you have at one time or another scratched your head over at least some of these questions and maybe even today. I was wondering today, what the heck can read this? All right, that was a general introduction to data preservation. What it is, why it's important, what sorts of things are issues in data curation? Now, in the next video, we're going to develop a more rigorous formal and precise characterization of data preservation.