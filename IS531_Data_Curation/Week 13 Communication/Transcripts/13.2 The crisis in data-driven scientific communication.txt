Welcome back everyone. This is the week on communication and data. It's the second video, titled "The crisis in data-driven scientific communication." I'm going to start summarizing a couple of things I said in the last video, then telling a story about a hypothetical scientist, Lisa, which illustrates what is sometimes called the explosion in scientific literature. We'll talk about some possible solutions to the problem created by that explosion, solutions that none of which will completely work and that sets us up for video three, where we will discuss an important solution often neglected. I said last time, showed this slide in the last video, scientific communication profoundly important in science, engineering, technology, business, anybody work with data. Nothing is really going to happen unless data gets noticed somehow. There's no point in collecting data. There's no point in analyzing data unless we use it to make something happen. And in science, that usually means publishing. Science, engineering, a variety of technical fields, and often in business as well, some sort of publishing has to occur if all this investment in data is going to actually pay off. Obvious the case in science, often the case in other fields as well. I also said last time, and this is important, that to understand the real importance of publishing, we need to recognize that it has effects in two directions. So, it comes out of research, your research results are published, but your research results are recorded and made available to other researchers, which means that your research results go into new research programs around the world. There is a crisis, a big crisis in scientific and technical publishing. It's a problem that is caused by data, caused by the enormous increase in the amount of data available to us, and the importance of data. It's also a crisis that I think can be addressed by data, but it's in the next video where we talk about solving the problem. This one's focused on the problem itself. So, let me tell a story. It's an imaginary story, my one opportunity to indulge in fiction. It won't be very impressive as fiction. So, Lisa, imagine that Lisa is born in January 2000. That means, today, she's 17, perhaps just starting college. And all of her life, she's been using the web, Google, Facebook, and smartphones. Most of these things were really mature by the time she was able to use them, when she was five, six, seven, eight for instance. So, she is really a digital native. Now, let's look ahead by eight years to 2026, imagine that Lisa has just finished her doctoral coursework in molecular biology, she's about to start her research. So, she goes to the library and walks up to the science reference desk. You might wonder at this point, why is she there? Does she need to know some fact? Does she need some resource? Does she need to know how to use a resource? She might begin saying to the reference librarian, "I'm studying the role of P53 in Huntington's disease." P53 is a gene with corresponding protein. And let's imagine that the reference librarian interrupts and says, "So, you'd like to find some articles to read on P53? " and they both laugh. Why do they laugh? Why would they laugh at that short exchange? So, why did they laugh? Because the reference librarian is making a joke. In 2026, no one is going to be looking for articles to read, at least not in science. In 2026, engaging with the scientific literature will, finally, in the words of Alan Kay be like "flying a plane through information space", and not at all like finding and reading articles, and it's not just innovative tools, it's going to make this happen, it's necessity. Here's the problem. So, what we're looking at in this slide is a KEGG map of genes and protein relationships, and it's just a small part of the world, a small part of the genomic world and an even smaller part is there in the red triangle, TP53, that's P53, small part of a small part. But, today there are nearly 80,000 articles on P53, not just mentioning P53 somewhere but mentioning P53 in the title or abstract, nearly 80,000 today. So, how many are there going to be in 2026 or 2036? So you might say that a tipping point has been reached here. Tipping point has already been reached. This quotation is from Barend Mons, who is a molecular biologist very well-known for his work on the topic of scientific collaboration and publication in molecular biology. And he says, "Nowadays, sets of relevant papers are identified that surpass human capability for reading, interpretation, and synthesis." He means that in the investigation of certain topics, the relevant papers that you must take into account actually surpass your capability for reading, interpretation, and synthesis. Despite the enormous degree of specialization that has occurred in the sciences, this is a problem. It's a big problem, and it's a problem that has been largely created by contemporary data generation, deluge of data, and the tools that help us generate that data, and of course, indirectly by the tools that we use to analyze that data and and that have made that generation of data so profoundly valuable. Don't believe me? Take a look at this graph. The blue line is total MEDLINE abstracts, and the brownish red line, I guess it is, are papers published specifically on the cell cycle. And you can see that there's an inflection around 1975, and then there is an incredibly sharp increase in 1990 that continues to go up very, very fast. This is data science staring us in the face right here. This is a positive but also a challenging result from data science because it is very, very difficult for researchers in this area to cope with this degree of rapid growth. It's a huge problem. Arguably, it changes science as we know it. So what can we do about it? One response that's well underway maturing perhaps even, still ways to go is text mining or literature mining. So, the idea is that instead of reading these papers, the relevant information would be extracted by software tools and made available in condensed form to scientists who need the information. So we're not going to be reading the paper left to right, top to bottom, humans reading the paper left to right, top to bottom. Instead, software tools are going to digest scientific papers and present the results, extracted information, to the human scientist or perhaps initially to other software tools, other bots who are going to continue to perhaps collect information from variety of sources and continue to condense and analyze. Another response is to help scientists read, and this has been called help developing tools for strategic reading. Both of these responses are needed. Both of them are underway. Both of them are important. I'm going to be talking in the next video about the second response tools for strategic reading.